<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MySQL on 街上的动物园</title><link>https://heeexy.com/tags/mysql/</link><description>Recent content in MySQL on 街上的动物园</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Heeexy</copyright><lastBuildDate>Sun, 13 Nov 2022 21:17:00 +0000</lastBuildDate><atom:link href="https://heeexy.com/tags/mysql/index.xml" rel="self" type="application/rss+xml"/><item><title>数据库如果断电，我们需不需要慌？</title><link>https://heeexy.com/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A6%82%E6%9E%9C%E6%96%AD%E7%94%B5%E6%88%91%E4%BB%AC%E9%9C%80%E4%B8%8D%E9%9C%80%E8%A6%81%E6%85%8C/</link><pubDate>Sun, 13 Nov 2022 21:17:00 +0000</pubDate><guid>https://heeexy.com/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A6%82%E6%9E%9C%E6%96%AD%E7%94%B5%E6%88%91%E4%BB%AC%E9%9C%80%E4%B8%8D%E9%9C%80%E8%A6%81%E6%85%8C/</guid><description>&lt;h1 id="序">
&lt;a href="#%e5%ba%8f">#&lt;/a>
序
&lt;/h1>&lt;p>生产环境我们时时刻刻在向数据库发送着写入、新增、删除数据的请求，不知道各位有没有和我一样的顾虑，如果服务器突然断电或者死机，数据会不会丢失，甚至数据库会不会挂了再也无法恢复？&lt;/p>
&lt;p>心大的同学可能会说，我们生产环境的数据有副本，不用慌！&lt;/p>
&lt;p>那么正在写入中的数据呢？写入请求发给了数据库，还没收到成功/失败的响应，这时候数据库断电，你慌不慌？&lt;/p>
&lt;p>&lt;img src="http://img.heeexy.com/database-crash-safe-1.png"
loading="lazy"
alt="Untitled"
>&lt;/p>
&lt;p>当然，作为数据库，自有它保障数据安全的方式，只要做好了合适的配置，就可以应对断电的情况。&lt;/p>
&lt;p>今天我们就以 Elasticsearch 和 MySQL 为例来了解下数据库是如何保障数据安全的。&lt;/p>
&lt;h1 id="原理">
&lt;a href="#%e5%8e%9f%e7%90%86">#&lt;/a>
原理
&lt;/h1>&lt;h2 id="elasticsearch">
&lt;a href="#elasticsearch">#&lt;/a>
Elasticsearch
&lt;/h2>&lt;p>数据在 lucene 中的主要写入流程上如下图所示，&lt;/p>
&lt;p>&lt;img src="http://img.heeexy.com/database-crash-safe-2.png"
loading="lazy"
alt="Untitled"
>&lt;/p>
&lt;p>从图上可以看出，只有 segment 落盘了，数据才是真正安全的。但是这会带来一个比较严重的问题：在 refresh 之后，commit 之前，数据已经可以被用户查到，然而断电后数据丢失，重启后这个数据无法被搜到。&lt;/p>
&lt;p>因此 es 设计了translog，每次数据的写入，会在分词、加入倒排索引等重逻辑的 lucene 操作之前，数据的原始信息率先写入 translog。这就是 WAL (write-ahead-logging) 机制。&lt;/p>
&lt;p>有了 translog 后，即使是没有落盘到 segment 的数据，崩溃想要恢复也有了依据，如下图所示，前2个阶段依靠 translog 恢复。&lt;/p>
&lt;p>&lt;img src="http://img.heeexy.com/database-crash-safe-3.png"
loading="lazy"
alt="Untitled"
>&lt;/p>
&lt;p>当然 translog 文件本身也会有 fsync 的问题，可以通过配置选择 translog 文件 fsync 的时机，而这个时机最终决定了数据的可恢复性。&lt;/p>
&lt;p>&lt;img src="http://img.heeexy.com/database-crash-safe-4.png"
loading="lazy"
alt="Untitled"
>&lt;/p>
&lt;p>Elasticsearch 比较常见的设置是：&lt;/p>
&lt;p>&lt;code>index.translog.durability=async&lt;/code>&lt;/p>
&lt;p>&lt;strong>&lt;code>index.translog.sync_interval=5s&lt;/code>&lt;/strong>&lt;/p>
&lt;p>这样配置下，最多可能丢失 5s 的数据。而 Elasticsearch 要保障数据支持崩溃恢复，比较极端的追求崩溃恢复的设置为：&lt;/p>
&lt;p>&lt;code>index.translog.durability=request&lt;/code>&lt;/p>
&lt;p>每个 request 都会进行数据落盘。&lt;/p>
&lt;h2 id="mysql">
&lt;a href="#mysql">#&lt;/a>
MySQL
&lt;/h2>&lt;p>数据更新操作在 MySQL中的流程如下图所示，&lt;/p>
&lt;p>&lt;img src="http://img.heeexy.com/database-crash-safe-5.png"
loading="lazy"
alt="Untitled"
>&lt;/p>
&lt;p>其中崩溃恢复的核心是 redo log，innodb_flush_log_at_trx_commit 参数设置为 1 时，可以保障每次事务 commit 的时候 redo log 刷到磁盘。&lt;/p>
&lt;p>&lt;img src="http://img.heeexy.com/database-crash-safe-6.png"
loading="lazy"
alt="Untitled"
>&lt;/p>
&lt;h2 id="对比">
&lt;a href="#%e5%af%b9%e6%af%94">#&lt;/a>
对比
&lt;/h2>&lt;h3 id="同">
&lt;a href="#%e5%90%8c">#&lt;/a>
同
&lt;/h3>&lt;ol>
&lt;li>为了提升性能，都充分利用了内存。由此也提升了数据安全问题的复杂度，需要保障内存中的数据在断电丢失后，有办法进行恢复。&lt;/li>
&lt;li>为了解决上面的问题，都利用了 WAL (write-ahead-logging) 机制。&lt;/li>
&lt;li>都需要关注 log 何时 fsync 到磁盘。&lt;/li>
&lt;/ol>
&lt;h3 id="异">
&lt;a href="#%e5%bc%82">#&lt;/a>
异
&lt;/h3>&lt;ol>
&lt;li>log 作用不同：
&lt;ul>
&lt;li>Elasticsearch 的 translog 用于崩溃恢复&lt;/li>
&lt;li>MySQL 的 redo log 用于崩溃恢复&lt;/li>
&lt;li>MySQL 的 binlog 不支持崩溃恢复，主要用于数据的增量备份。可以支持主从复制，可以支持数据回溯，配合全量的快照，可以回到之前某一时刻的状态。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>log 内容不同：
&lt;ul>
&lt;li>translog 记录请求原始信息。&lt;/li>
&lt;li>redo log 记录结构化之后的，具体 page 中的修改信息，详情可以参见&lt;a class="link" href="http://catkang.github.io/2020/02/27/mysql-redo.html" target="_blank" rel="noopener"
>庖丁解InnoDB之REDO LOG&lt;/a>。&lt;/li>
&lt;li>binlog 记录的内容和 translog 更为类似，它的 statement 格式记录的是原始语句。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>log 保存时长不同：
&lt;ul>
&lt;li>translog 在每次 flush 完后都会清空，体积很小。&lt;/li>
&lt;li>redo log 循环使用ib_logfile0、ib_logfile1… 体积也不会特别大。（仅讨论 crash-safe 问题的话，这一点应该属于相同点）&lt;/li>
&lt;li>binlog 可以保存很久，时长完全取决于用户想要数据可追溯多久。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>我们再重点关注下为什么 translog 和 redo log 同样用于 crash-safe，但记录的信息不同。&lt;/p>
&lt;p>我想了很久，苦寻无果后翻阅 lucene 文档中查找 translog 信息时突然想起来，其实这个问题很简单。&lt;/p>
&lt;p>因为他们所处的层级不同。&lt;/p>
&lt;p>Elasticsearch 以 lucene 为引擎，但 lucene 本身没有 translog，因此 Elasticsearch 要在较高层级记录请求信息。而 InnoDB 作为 MySQL 的引擎，自身就可以拿到本次请求的数据结构化之后的信息。&lt;/p>
&lt;p>&lt;img src="http://img.heeexy.com/database-crash-safe-7.png"
loading="lazy"
alt="Untitled"
>&lt;/p>
&lt;h1 id="review">
&lt;a href="#review">#&lt;/a>
Review
&lt;/h1>&lt;ol>
&lt;li>
&lt;p>面对业界共同的问题，总是有相似的解决方案可供参考。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>弄清楚自己的需求和实际的数据库配置之后，数据库的服务器断电不用慌。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>回到我们最开始的一张图，数据库虽可以做到 crash-safe ，但不代表我们对重要业务可以把心放到肚子里。因为：&lt;/p>
&lt;ol>
&lt;li>MySQL 对在 crash 后对事务是否需要数据恢复的依据是 binlog 是否完整，无论 redo log 是否达到了 commit 状态，即无论这个事务是否最终提交完成，响应是否到达客户端。&lt;/li>
&lt;li>图上的 request / response 其实本身就并不可靠。&lt;/li>
&lt;/ol>
&lt;p>因此对于极其重要的业务来说，极端场景的业务完整性仍然需要保持关注。&lt;/p>
&lt;p>&lt;img src="http://img.heeexy.com/database-crash-safe-8.png"
loading="lazy"
alt="Untitled"
>&lt;/p>
&lt;/li>
&lt;/ol></description></item></channel></rss>