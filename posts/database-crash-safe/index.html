<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>数据库如果断电，我们需不需要慌？ | 网站标题</title>
<meta name=keywords content="MySQL,Elasticsearch,crash-safe"><meta name=description content="序 生产环境我们时时刻刻在向数据库发送着写入、新增、删除数据的请求，不知道各位有没有和我一样的顾虑，如果服务器突然断电或者死机，数据会不会丢失，甚至数据库会不会挂了再也无法恢复？
心大的同学可能会说，我们生产环境的数据有副本，不用慌！
那么正在写入中的数据呢？写入请求发给了数据库，还没收到成功/失败的响应，这时候数据库断电，你慌不慌？
当然，作为数据库，自有它保障数据安全的方式，只要做好了合适的配置，就可以应对断电的情况。
今天我们就以 Elasticsearch 和 MySQL 为例来了解下数据库是如何保障数据安全的。
原理 Elasticsearch 数据在 lucene 中的主要写入流程上如下图所示，
从图上可以看出，只有 segment 落盘了，数据才是真正安全的。但是这会带来一个比较严重的问题：在 refresh 之后，commit 之前，数据已经可以被用户查到，然而断电后数据丢失，重启后这个数据无法被搜到。
因此 es 设计了translog，每次数据的写入，会在分词、加入倒排索引等重逻辑的 lucene 操作之前，数据的原始信息率先写入 translog。这就是 WAL (write-ahead-logging) 机制。
有了 translog 后，即使是没有落盘到 segment 的数据，崩溃想要恢复也有了依据，如下图所示，前2个阶段依靠 translog 恢复。
当然 translog 文件本身也会有 fsync 的问题，可以通过配置选择 translog 文件 fsync 的时机，而这个时机最终决定了数据的可恢复性。
Elasticsearch 比较常见的设置是：
index.translog.durability=async
index.translog.sync_interval=5s
这样配置下，最多可能丢失 5s 的数据。而 Elasticsearch 要保障数据支持崩溃恢复，比较极端的追求崩溃恢复的设置为：
index.translog.durability=request
每个 request 都会进行数据落盘。
MySQL 数据更新操作在 MySQL中的流程如下图所示，
其中崩溃恢复的核心是 redo log，innodb_flush_log_at_trx_commit 参数设置为 1 时，可以保障每次事务 commit 的时候 redo log 刷到磁盘。"><meta name=author content><link rel=canonical href=https://heeexy.com/posts/database-crash-safe/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://heeexy.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://heeexy.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://heeexy.com/favicon-32x32.png><link rel=apple-touch-icon href=https://heeexy.com/apple-touch-icon.png><link rel=mask-icon href=https://heeexy.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://heeexy.com/posts/database-crash-safe/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="数据库如果断电，我们需不需要慌？"><meta property="og:description" content="序 生产环境我们时时刻刻在向数据库发送着写入、新增、删除数据的请求，不知道各位有没有和我一样的顾虑，如果服务器突然断电或者死机，数据会不会丢失，甚至数据库会不会挂了再也无法恢复？
心大的同学可能会说，我们生产环境的数据有副本，不用慌！
那么正在写入中的数据呢？写入请求发给了数据库，还没收到成功/失败的响应，这时候数据库断电，你慌不慌？
当然，作为数据库，自有它保障数据安全的方式，只要做好了合适的配置，就可以应对断电的情况。
今天我们就以 Elasticsearch 和 MySQL 为例来了解下数据库是如何保障数据安全的。
原理 Elasticsearch 数据在 lucene 中的主要写入流程上如下图所示，
从图上可以看出，只有 segment 落盘了，数据才是真正安全的。但是这会带来一个比较严重的问题：在 refresh 之后，commit 之前，数据已经可以被用户查到，然而断电后数据丢失，重启后这个数据无法被搜到。
因此 es 设计了translog，每次数据的写入，会在分词、加入倒排索引等重逻辑的 lucene 操作之前，数据的原始信息率先写入 translog。这就是 WAL (write-ahead-logging) 机制。
有了 translog 后，即使是没有落盘到 segment 的数据，崩溃想要恢复也有了依据，如下图所示，前2个阶段依靠 translog 恢复。
当然 translog 文件本身也会有 fsync 的问题，可以通过配置选择 translog 文件 fsync 的时机，而这个时机最终决定了数据的可恢复性。
Elasticsearch 比较常见的设置是：
index.translog.durability=async
index.translog.sync_interval=5s
这样配置下，最多可能丢失 5s 的数据。而 Elasticsearch 要保障数据支持崩溃恢复，比较极端的追求崩溃恢复的设置为：
index.translog.durability=request
每个 request 都会进行数据落盘。
MySQL 数据更新操作在 MySQL中的流程如下图所示，
其中崩溃恢复的核心是 redo log，innodb_flush_log_at_trx_commit 参数设置为 1 时，可以保障每次事务 commit 的时候 redo log 刷到磁盘。"><meta property="og:type" content="article"><meta property="og:url" content="https://heeexy.com/posts/database-crash-safe/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-13T21:17:00+00:00"><meta property="article:modified_time" content="2022-11-13T21:17:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="数据库如果断电，我们需不需要慌？"><meta name=twitter:description content="序 生产环境我们时时刻刻在向数据库发送着写入、新增、删除数据的请求，不知道各位有没有和我一样的顾虑，如果服务器突然断电或者死机，数据会不会丢失，甚至数据库会不会挂了再也无法恢复？
心大的同学可能会说，我们生产环境的数据有副本，不用慌！
那么正在写入中的数据呢？写入请求发给了数据库，还没收到成功/失败的响应，这时候数据库断电，你慌不慌？
当然，作为数据库，自有它保障数据安全的方式，只要做好了合适的配置，就可以应对断电的情况。
今天我们就以 Elasticsearch 和 MySQL 为例来了解下数据库是如何保障数据安全的。
原理 Elasticsearch 数据在 lucene 中的主要写入流程上如下图所示，
从图上可以看出，只有 segment 落盘了，数据才是真正安全的。但是这会带来一个比较严重的问题：在 refresh 之后，commit 之前，数据已经可以被用户查到，然而断电后数据丢失，重启后这个数据无法被搜到。
因此 es 设计了translog，每次数据的写入，会在分词、加入倒排索引等重逻辑的 lucene 操作之前，数据的原始信息率先写入 translog。这就是 WAL (write-ahead-logging) 机制。
有了 translog 后，即使是没有落盘到 segment 的数据，崩溃想要恢复也有了依据，如下图所示，前2个阶段依靠 translog 恢复。
当然 translog 文件本身也会有 fsync 的问题，可以通过配置选择 translog 文件 fsync 的时机，而这个时机最终决定了数据的可恢复性。
Elasticsearch 比较常见的设置是：
index.translog.durability=async
index.translog.sync_interval=5s
这样配置下，最多可能丢失 5s 的数据。而 Elasticsearch 要保障数据支持崩溃恢复，比较极端的追求崩溃恢复的设置为：
index.translog.durability=request
每个 request 都会进行数据落盘。
MySQL 数据更新操作在 MySQL中的流程如下图所示，
其中崩溃恢复的核心是 redo log，innodb_flush_log_at_trx_commit 参数设置为 1 时，可以保障每次事务 commit 的时候 redo log 刷到磁盘。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://heeexy.com/posts/"},{"@type":"ListItem","position":2,"name":"数据库如果断电，我们需不需要慌？","item":"https://heeexy.com/posts/database-crash-safe/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"数据库如果断电，我们需不需要慌？","name":"数据库如果断电，我们需不需要慌？","description":"序 生产环境我们时时刻刻在向数据库发送着写入、新增、删除数据的请求，不知道各位有没有和我一样的顾虑，如果服务器突然断电或者死机，数据会不会丢失，甚至数据库会不会挂了再也无法恢复？\n心大的同学可能会说，我们生产环境的数据有副本，不用慌！\n那么正在写入中的数据呢？写入请求发给了数据库，还没收到成功/失败的响应，这时候数据库断电，你慌不慌？\n当然，作为数据库，自有它保障数据安全的方式，只要做好了合适的配置，就可以应对断电的情况。\n今天我们就以 Elasticsearch 和 MySQL 为例来了解下数据库是如何保障数据安全的。\n原理 Elasticsearch 数据在 lucene 中的主要写入流程上如下图所示，\n从图上可以看出，只有 segment 落盘了，数据才是真正安全的。但是这会带来一个比较严重的问题：在 refresh 之后，commit 之前，数据已经可以被用户查到，然而断电后数据丢失，重启后这个数据无法被搜到。\n因此 es 设计了translog，每次数据的写入，会在分词、加入倒排索引等重逻辑的 lucene 操作之前，数据的原始信息率先写入 translog。这就是 WAL (write-ahead-logging) 机制。\n有了 translog 后，即使是没有落盘到 segment 的数据，崩溃想要恢复也有了依据，如下图所示，前2个阶段依靠 translog 恢复。\n当然 translog 文件本身也会有 fsync 的问题，可以通过配置选择 translog 文件 fsync 的时机，而这个时机最终决定了数据的可恢复性。\nElasticsearch 比较常见的设置是：\nindex.translog.durability=async\nindex.translog.sync_interval=5s\n这样配置下，最多可能丢失 5s 的数据。而 Elasticsearch 要保障数据支持崩溃恢复，比较极端的追求崩溃恢复的设置为：\nindex.translog.durability=request\n每个 request 都会进行数据落盘。\nMySQL 数据更新操作在 MySQL中的流程如下图所示，\n其中崩溃恢复的核心是 redo log，innodb_flush_log_at_trx_commit 参数设置为 1 时，可以保障每次事务 commit 的时候 redo log 刷到磁盘。","keywords":["MySQL","Elasticsearch","crash-safe"],"articleBody":"序 生产环境我们时时刻刻在向数据库发送着写入、新增、删除数据的请求，不知道各位有没有和我一样的顾虑，如果服务器突然断电或者死机，数据会不会丢失，甚至数据库会不会挂了再也无法恢复？\n心大的同学可能会说，我们生产环境的数据有副本，不用慌！\n那么正在写入中的数据呢？写入请求发给了数据库，还没收到成功/失败的响应，这时候数据库断电，你慌不慌？\n当然，作为数据库，自有它保障数据安全的方式，只要做好了合适的配置，就可以应对断电的情况。\n今天我们就以 Elasticsearch 和 MySQL 为例来了解下数据库是如何保障数据安全的。\n原理 Elasticsearch 数据在 lucene 中的主要写入流程上如下图所示，\n从图上可以看出，只有 segment 落盘了，数据才是真正安全的。但是这会带来一个比较严重的问题：在 refresh 之后，commit 之前，数据已经可以被用户查到，然而断电后数据丢失，重启后这个数据无法被搜到。\n因此 es 设计了translog，每次数据的写入，会在分词、加入倒排索引等重逻辑的 lucene 操作之前，数据的原始信息率先写入 translog。这就是 WAL (write-ahead-logging) 机制。\n有了 translog 后，即使是没有落盘到 segment 的数据，崩溃想要恢复也有了依据，如下图所示，前2个阶段依靠 translog 恢复。\n当然 translog 文件本身也会有 fsync 的问题，可以通过配置选择 translog 文件 fsync 的时机，而这个时机最终决定了数据的可恢复性。\nElasticsearch 比较常见的设置是：\nindex.translog.durability=async\nindex.translog.sync_interval=5s\n这样配置下，最多可能丢失 5s 的数据。而 Elasticsearch 要保障数据支持崩溃恢复，比较极端的追求崩溃恢复的设置为：\nindex.translog.durability=request\n每个 request 都会进行数据落盘。\nMySQL 数据更新操作在 MySQL中的流程如下图所示，\n其中崩溃恢复的核心是 redo log，innodb_flush_log_at_trx_commit 参数设置为 1 时，可以保障每次事务 commit 的时候 redo log 刷到磁盘。\n对比 同 为了提升性能，都充分利用了内存。由此也提升了数据安全问题的复杂度，需要保障内存中的数据在断电丢失后，有办法进行恢复。 为了解决上面的问题，都利用了 WAL (write-ahead-logging) 机制。 都需要关注 log 何时 fsync 到磁盘。 异 log 作用不同： Elasticsearch 的 translog 用于崩溃恢复 MySQL 的 redo log 用于崩溃恢复 MySQL 的 binlog 不支持崩溃恢复，主要用于数据的增量备份。可以支持主从复制，可以支持数据回溯，配合全量的快照，可以回到之前某一时刻的状态。 log 内容不同： translog 记录请求原始信息。 redo log 记录结构化之后的，具体 page 中的修改信息，详情可以参见庖丁解InnoDB之REDO LOG。 binlog 记录的内容和 translog 更为类似，它的 statement 格式记录的是原始语句。 log 保存时长不同： translog 在每次 flush 完后都会清空，体积很小。 redo log 循环使用ib_logfile0、ib_logfile1… 体积也不会特别大。（仅讨论 crash-safe 问题的话，这一点应该属于相同点） binlog 可以保存很久，时长完全取决于用户想要数据可追溯多久。 我们再重点关注下为什么 translog 和 redo log 同样用于 crash-safe，但记录的信息不同。\n我想了很久，苦寻无果后翻阅 lucene 文档中查找 translog 信息时突然想起来，其实这个问题很简单。\n因为他们所处的层级不同。\nElasticsearch 以 lucene 为引擎，但 lucene 本身没有 translog，因此 Elasticsearch 要在较高层级记录请求信息。而 InnoDB 作为 MySQL 的引擎，自身就可以拿到本次请求的数据结构化之后的信息。\nReview 面对业界共同的问题，总是有相似的解决方案可供参考。\n弄清楚自己的需求和实际的数据库配置之后，数据库的服务器断电不用慌。\n回到我们最开始的一张图，数据库虽可以做到 crash-safe ，但不代表我们对重要业务可以把心放到肚子里。因为：\nMySQL 对在 crash 后对事务是否需要数据恢复的依据是 binlog 是否完整，无论 redo log 是否达到了 commit 状态，即无论这个事务是否最终提交完成，响应是否到达客户端。 图上的 request / response 其实本身就并不可靠。 因此对于极其重要的业务来说，极端场景的业务完整性仍然需要保持关注。\n","wordCount":"180","inLanguage":"en","datePublished":"2022-11-13T21:17:00Z","dateModified":"2022-11-13T21:17:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://heeexy.com/posts/database-crash-safe/"},"publisher":{"@type":"Organization","name":"网站标题","logo":{"@type":"ImageObject","url":"https://heeexy.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://heeexy.com/ accesskey=h title="网站标题 (Alt + H)">网站标题</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">数据库如果断电，我们需不需要慌？</h1><div class=post-meta><span title='2022-11-13 21:17:00 +0000 UTC'>November 13, 2022</span></div></header><div class=post-content><h1 id=序>序<a hidden class=anchor aria-hidden=true href=#序>#</a></h1><p>生产环境我们时时刻刻在向数据库发送着写入、新增、删除数据的请求，不知道各位有没有和我一样的顾虑，如果服务器突然断电或者死机，数据会不会丢失，甚至数据库会不会挂了再也无法恢复？</p><p>心大的同学可能会说，我们生产环境的数据有副本，不用慌！</p><p>那么正在写入中的数据呢？写入请求发给了数据库，还没收到成功/失败的响应，这时候数据库断电，你慌不慌？</p><p><img loading=lazy src=http://img.heeexy.com/database-crash-safe-1.png alt=Untitled></p><p>当然，作为数据库，自有它保障数据安全的方式，只要做好了合适的配置，就可以应对断电的情况。</p><p>今天我们就以 Elasticsearch 和 MySQL 为例来了解下数据库是如何保障数据安全的。</p><h1 id=原理>原理<a hidden class=anchor aria-hidden=true href=#原理>#</a></h1><h2 id=elasticsearch>Elasticsearch<a hidden class=anchor aria-hidden=true href=#elasticsearch>#</a></h2><p>数据在 lucene 中的主要写入流程上如下图所示，</p><p><img loading=lazy src=http://img.heeexy.com/database-crash-safe-2.png alt=Untitled></p><p>从图上可以看出，只有 segment 落盘了，数据才是真正安全的。但是这会带来一个比较严重的问题：在 refresh 之后，commit 之前，数据已经可以被用户查到，然而断电后数据丢失，重启后这个数据无法被搜到。</p><p>因此 es 设计了translog，每次数据的写入，会在分词、加入倒排索引等重逻辑的 lucene 操作之前，数据的原始信息率先写入 translog。这就是 WAL (write-ahead-logging) 机制。</p><p>有了 translog 后，即使是没有落盘到 segment 的数据，崩溃想要恢复也有了依据，如下图所示，前2个阶段依靠 translog 恢复。</p><p><img loading=lazy src=http://img.heeexy.com/database-crash-safe-3.png alt=Untitled></p><p>当然 translog 文件本身也会有 fsync 的问题，可以通过配置选择 translog 文件 fsync 的时机，而这个时机最终决定了数据的可恢复性。</p><p><img loading=lazy src=http://img.heeexy.com/database-crash-safe-4.png alt=Untitled></p><p>Elasticsearch 比较常见的设置是：</p><p><code>index.translog.durability=async</code></p><p><strong><code>index.translog.sync_interval=5s</code></strong></p><p>这样配置下，最多可能丢失 5s 的数据。而 Elasticsearch 要保障数据支持崩溃恢复，比较极端的追求崩溃恢复的设置为：</p><p><code>index.translog.durability=request</code></p><p>每个 request 都会进行数据落盘。</p><h2 id=mysql>MySQL<a hidden class=anchor aria-hidden=true href=#mysql>#</a></h2><p>数据更新操作在 MySQL中的流程如下图所示，</p><p><img loading=lazy src=http://img.heeexy.com/database-crash-safe-5.png alt=Untitled></p><p>其中崩溃恢复的核心是 redo log，innodb_flush_log_at_trx_commit 参数设置为 1 时，可以保障每次事务 commit 的时候 redo log 刷到磁盘。</p><p><img loading=lazy src=http://img.heeexy.com/database-crash-safe-6.png alt=Untitled></p><h2 id=对比>对比<a hidden class=anchor aria-hidden=true href=#对比>#</a></h2><h3 id=同>同<a hidden class=anchor aria-hidden=true href=#同>#</a></h3><ol><li>为了提升性能，都充分利用了内存。由此也提升了数据安全问题的复杂度，需要保障内存中的数据在断电丢失后，有办法进行恢复。</li><li>为了解决上面的问题，都利用了 WAL (write-ahead-logging) 机制。</li><li>都需要关注 log 何时 fsync 到磁盘。</li></ol><h3 id=异>异<a hidden class=anchor aria-hidden=true href=#异>#</a></h3><ol><li>log 作用不同：<ul><li>Elasticsearch 的 translog 用于崩溃恢复</li><li>MySQL 的 redo log 用于崩溃恢复</li><li>MySQL 的 binlog 不支持崩溃恢复，主要用于数据的增量备份。可以支持主从复制，可以支持数据回溯，配合全量的快照，可以回到之前某一时刻的状态。</li></ul></li><li>log 内容不同：<ul><li>translog 记录请求原始信息。</li><li>redo log 记录结构化之后的，具体 page 中的修改信息，详情可以参见<a href=http://catkang.github.io/2020/02/27/mysql-redo.html>庖丁解InnoDB之REDO LOG</a>。</li><li>binlog 记录的内容和 translog 更为类似，它的 statement 格式记录的是原始语句。</li></ul></li><li>log 保存时长不同：<ul><li>translog 在每次 flush 完后都会清空，体积很小。</li><li>redo log 循环使用ib_logfile0、ib_logfile1… 体积也不会特别大。（仅讨论 crash-safe 问题的话，这一点应该属于相同点）</li><li>binlog 可以保存很久，时长完全取决于用户想要数据可追溯多久。</li></ul></li></ol><p>我们再重点关注下为什么 translog 和 redo log 同样用于 crash-safe，但记录的信息不同。</p><p>我想了很久，苦寻无果后翻阅 lucene 文档中查找 translog 信息时突然想起来，其实这个问题很简单。</p><p>因为他们所处的层级不同。</p><p>Elasticsearch 以 lucene 为引擎，但 lucene 本身没有 translog，因此 Elasticsearch 要在较高层级记录请求信息。而 InnoDB 作为 MySQL 的引擎，自身就可以拿到本次请求的数据结构化之后的信息。</p><p><img loading=lazy src=http://img.heeexy.com/database-crash-safe-7.png alt=Untitled></p><h1 id=review>Review<a hidden class=anchor aria-hidden=true href=#review>#</a></h1><ol><li><p>面对业界共同的问题，总是有相似的解决方案可供参考。</p></li><li><p>弄清楚自己的需求和实际的数据库配置之后，数据库的服务器断电不用慌。</p></li><li><p>回到我们最开始的一张图，数据库虽可以做到 crash-safe ，但不代表我们对重要业务可以把心放到肚子里。因为：</p><ol><li>MySQL 对在 crash 后对事务是否需要数据恢复的依据是 binlog 是否完整，无论 redo log 是否达到了 commit 状态，即无论这个事务是否最终提交完成，响应是否到达客户端。</li><li>图上的 request / response 其实本身就并不可靠。</li></ol><p>因此对于极其重要的业务来说，极端场景的业务完整性仍然需要保持关注。</p><p><img loading=lazy src=http://img.heeexy.com/database-crash-safe-8.png alt=Untitled></p></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://heeexy.com/tags/mysql/>MySQL</a></li><li><a href=https://heeexy.com/tags/elasticsearch/>Elasticsearch</a></li><li><a href=https://heeexy.com/tags/crash-safe/>Crash-Safe</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://heeexy.com/>网站标题</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>